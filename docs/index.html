<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="refresh" content="30">
    <title>MentorAI Evaluation Dashboard - 20260121_104804</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: #f3f4f6;
            color: #1f2937;
            line-height: 1.5;
            padding: 2rem;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 2rem;
            flex-wrap: wrap;
            gap: 1rem;
        }
        h1 {
            font-size: 1.5rem;
            font-weight: 600;
        }
        .meta {
            display: flex;
            align-items: center;
            gap: 1rem;
            font-size: 0.875rem;
            color: #6b7280;
        }
        .badge {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 9999px;
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            color: white;
        }
        .cards {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin-bottom: 2rem;
        }
        .card {
            background: white;
            padding: 1.5rem;
            border-radius: 0.5rem;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        .card-label {
            font-size: 0.875rem;
            color: #6b7280;
            margin-bottom: 0.5rem;
        }
        .card-value {
            font-size: 2rem;
            font-weight: 700;
        }
        .card-value.pass {
            color: #10b981;
        }
        .card-value.fail {
            color: #ef4444;
        }
        .section {
            background: white;
            border-radius: 0.5rem;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            margin-bottom: 2rem;
        }
        .section-header {
            padding: 1rem 1.5rem;
            border-bottom: 1px solid #e5e7eb;
            font-weight: 600;
        }
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            padding: 0.75rem 1rem;
            text-align: left;
            border-bottom: 1px solid #e5e7eb;
        }
        th {
            font-weight: 600;
            font-size: 0.875rem;
            color: #6b7280;
            background: #f9fafb;
        }
        tr:last-child td {
            border-bottom: none;
        }
        .progress-bar {
            width: 100%;
            height: 0.5rem;
            background: #e5e7eb;
            border-radius: 9999px;
            overflow: hidden;
        }
        .progress-fill {
            height: 100%;
            border-radius: 9999px;
            transition: width 0.3s ease;
        }
        .progress-fill.high {
            background: #10b981;
        }
        .progress-fill.medium {
            background: #f59e0b;
        }
        .progress-fill.low {
            background: #ef4444;
        }
        .verdict {
            display: inline-block;
            padding: 0.125rem 0.5rem;
            border-radius: 0.25rem;
            font-size: 0.75rem;
            font-weight: 600;
        }
        .verdict.pass {
            background: #d1fae5;
            color: #065f46;
        }
        .verdict.fail {
            background: #fee2e2;
            color: #991b1b;
        }
        .verdict.pending {
            background: #e5e7eb;
            color: #4b5563;
        }
        .expandable {
            cursor: pointer;
        }
        .expandable:hover {
            background: #f9fafb;
        }
        .details {
            display: none;
            background: #f9fafb;
        }
        .details.open {
            display: table-row;
        }
        .details-content {
            padding: 1rem;
            font-size: 0.875rem;
        }
        .quality-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 0.75rem 1.5rem;
            background: #f9fafb;
            padding: 1rem;
            border-radius: 0.375rem;
            border: 1px solid #e5e7eb;
        }
        .quality-item {
            display: flex;
            flex-direction: column;
            gap: 0.25rem;
        }
        .quality-item span:first-child {
            font-weight: 500;
            color: #374151;
            text-transform: capitalize;
        }
        .quality-item span:last-child {
            font-size: 0.875rem;
            color: #10b981;
            font-weight: 600;
        }
        .timestamp {
            font-size: 0.75rem;
            color: #9ca3af;
        }
        footer {
            text-align: center;
            padding: 1rem;
            color: #9ca3af;
            font-size: 0.75rem;
        }
        /* Evidence display styles */
        .evidence-section {
            margin-top: 1rem;
            border-top: 1px solid #e5e7eb;
            padding-top: 1rem;
        }
        .evidence-section h4 {
            font-size: 0.875rem;
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #374151;
        }
        .criterion-item {
            margin-bottom: 1rem;
            padding: 0.75rem;
            border-radius: 0.375rem;
            border-left: 3px solid;
        }
        .criterion-item.pass {
            background: #f0fdf4;
            border-left-color: #10b981;
        }
        .criterion-item.fail {
            background: #fef2f2;
            border-left-color: #ef4444;
        }
        .criterion-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.5rem;
        }
        .criterion-code {
            font-weight: 600;
            font-size: 0.875rem;
        }
        .criterion-item.pass .criterion-code {
            color: #065f46;
        }
        .criterion-item.fail .criterion-code {
            color: #991b1b;
        }
        .evidence-text {
            font-size: 0.8125rem;
            color: #4b5563;
            line-height: 1.6;
            font-style: italic;
        }
        .evidence-text::before {
            content: '"';
        }
        .evidence-text::after {
            content: '"';
        }
        .judge-section {
            margin-top: 1.5rem;
        }
        .judge-section h5 {
            font-size: 0.8125rem;
            font-weight: 600;
            color: #6b7280;
            margin-bottom: 0.5rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }
        .failed-summary {
            background: #fef2f2;
            border: 1px solid #fecaca;
            border-radius: 0.375rem;
            padding: 0.75rem;
            margin-bottom: 1rem;
        }
        .failed-summary-title {
            font-weight: 600;
            color: #991b1b;
            font-size: 0.875rem;
            margin-bottom: 0.5rem;
        }
        .toggle-evidence {
            font-size: 0.75rem;
            color: #6b7280;
            cursor: pointer;
            text-decoration: underline;
        }
        .toggle-evidence:hover {
            color: #374151;
        }
        .criteria-list {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
        }
        .criteria-list.expanded {
            max-height: 2000px;
        }
        /* Expandable criteria rows */
        .criteria-expand-row {
            cursor: pointer;
        }
        .criteria-expand-row:hover {
            background: #f9fafb;
        }
        .criteria-expand-row td:first-child::before {
            content: 'â–¶';
            display: inline-block;
            margin-right: 0.5rem;
            font-size: 0.625rem;
            transition: transform 0.2s ease;
            color: #9ca3af;
        }
        .criteria-expand-row.open td:first-child::before {
            transform: rotate(90deg);
        }
        .criteria-details-row {
            display: none;
            background: #f9fafb;
        }
        .criteria-details-row.open {
            display: table-row;
        }
        .persona-tag {
            font-size: 0.75rem;
            background: #e0e7ff;
            color: #4338ca;
            padding: 0.125rem 0.5rem;
            border-radius: 0.25rem;
            font-weight: 500;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>MentorAI Evaluation Dashboard</h1>
            <div class="meta">
                <span>Run: <strong>20260121_104804</strong></span>
                <span class="badge" style="background: #10b981">Complete</span>
                <span class="timestamp">Updated: 2026-01-21T10:56:58.213370</span>
            </div>
        </header>

        <div class="cards">
            <div class="card">
                <div class="card-label">Critical Pass Rate</div>
                <div class="card-value pass">100.0%</div>
                <div class="card-label">6/6 passed</div>
            </div>
            <div class="card">
                <div class="card-label">Quality Average</div>
                <div class="card-value">95.6%</div>
                <div class="card-label">109/114 criteria</div>
            </div>
            <div class="card">
                <div class="card-label">Progress</div>
                <div class="card-value">6/6</div>
                <div class="card-label">conversations evaluated</div>
            </div>
        </div>

        <div class="section">
            <div class="section-header">Per-Criteria Results</div>
            <table>
                <thead id="criteria-header">
                </thead>
                <tbody id="criteria-table">
                </tbody>
            </table>
        </div>

        <div class="section">
            <div class="section-header">Per-Conversation Results</div>
            <table>
                <thead>
                    <tr>
                        <th>ID</th>
                        <th>Persona</th>
                        <th>Critical</th>
                        <th>Quality Score</th>
                        <th>Status</th>
                    </tr>
                </thead>
                <tbody id="conversations">
                </tbody>
            </table>
        </div>

        <footer>
            Auto-refreshes every 30 seconds when hosted. Last generated: 2026-01-21T10:56:58.554879
        </footer>
    </div>

    <script>
        const manifest = {
  "run_id": "20260121_104804",
  "timestamp": "2026-01-21T10:56:58.213370",
  "status": "complete",
  "config": {
    "project": "MentorAI-Eval",
    "dataset": "master-eval",
    "run_filter": "MentorAI Evaluation Conversation",
    "tag": null,
    "model": "claude-opus-4-5-20251101",
    "limit": 1000,
    "stage": "all",
    "validation": false,
    "quality_judges": [
      "session_setup",
      "modeling_quality",
      "coaching_quality",
      "sbi_content",
      "adaptive_pacing",
      "conversational_quality"
    ],
    "total_conversations": 6
  },
  "conversations": [
    {
      "langsmith_id": "e2206591-e8e0-4eac-a481-e66f8b60feba",
      "short_id": "e2206591",
      "source_type": "dataset",
      "critical_verdict": "PASS",
      "critical_json": {
        "criteria": {
          "B-01": {
            "verdict": "PASS",
            "evidence": "Mentor provides complete SBI example: 'In Tuesday's standup, while I was sharing the API outage update, you started talking while I was mid-sentence and continued for about a minute; I felt sidelined and lost my train of thought, and I skipped mentioning the rollback plan, so QA didn't get the heads-up.'"
          },
          "C-01": {
            "verdict": "PASS",
            "evidence": "Mentor quotes specific problematic language: 'swap the labels (\"dismissive,\" \"brushing off\") for the exact words you heard' and 'the impact isn't owned\u2014\"made me look unprepared,\" \"undermined my role,\" and \"caused confusion\" are judgments or about others' perceptions'"
          },
          "C-03": {
            "verdict": "PASS",
            "evidence": "Mentor explicitly requests revisions multiple times: 'Rewrite the impact so it names what you felt...' and 'Anchor to the specific demo\u2014e.g., \"In Monday's Acme demo\"\u2014and resend the full message with that fix. Can you revise and share it?'"
          },
          "D-01": {
            "verdict": "PASS",
            "evidence": "When learner wrote 'design reviews lately' and 'our client demos lately', mentor caught both: 'Replace \"design reviews lately\" with a single, named moment' and 'The anchor misses: \"our client demos lately\" isn't a single moment.'"
          },
          "D-02": {
            "verdict": "PASS",
            "evidence": "Mentor catches judgment words multiple times: 'If you couldn't use the label \"dismissive,\" what exact words or actions from that moment would you name instead?' and 'swap the labels (\"dismissive,\" \"brushing off\") for the exact words you heard'"
          },
          "D-03": {
            "verdict": "PASS",
            "evidence": "When learner wrote 'made me look unprepared and undermined my role...caused confusion', mentor identified: 'the impact isn't owned\u2014\"made me look unprepared,\" \"undermined my role,\" and \"caused confusion\" are judgments or about others' perceptions, not your felt experience'"
          },
          "E-03": {
            "verdict": "N/A",
            "evidence": "Learner never asked mentor to provide answers or do the work for them; learner engaged with all revision requests independently."
          }
        },
        "overall": {
          "verdict": "PASS",
          "summary": "The mentor demonstrated strong cognitive apprenticeship tutoring by modeling SBI, providing specific feedback with quoted language, requesting revisions, and catching all error types (vague situations, judgment leakage, and accusatory impact).",
          "passed_count": 6,
          "failed_count": 0,
          "na_count": 1,
          "failed_criteria": []
        },
        "_metadata": {
          "judge_id": "critical_criteria",
          "conversation_id": "e2206591",
          "evaluated_at": "2026-01-21T10:48:25.146797"
        }
      },
      "quality_results": {
        "session_setup": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "A-01": {
                "verdict": "PASS",
                "evidence": "Mentor states: 'We're working on delivering peer feedback using SBI in a professional context. Success looks like you producing two complete attempts that anchor to a real moment, name observable behavior, and use owned impact language'"
              },
              "A-02": {
                "verdict": "PASS",
                "evidence": "Mentor signals transition: 'I'll demonstrate first\u2014ready to dive in?' and later 'Ready for a full attempt?' and 'Second rep\u2014variation on yours with higher stakes.'"
              },
              "A-03": {
                "verdict": "PASS",
                "evidence": "Scenarios include specific workplace situations: 'Thursday's design review' with a colleague interrupting during a testing plan explanation, and 'Monday's client demo with Acme' where a manager cuts in during a client question\u2014both have plausible interpersonal dynamics and specific details."
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "session_setup",
              "conversation_id": "e2206591",
              "evaluated_at": "2026-01-21T10:48:34.422808"
            }
          }
        },
        "modeling_quality": {
          "passed": 2,
          "total": 4,
          "json": {
            "criteria": {
              "B-02": {
                "verdict": "FAIL",
                "evidence": "Mentor provides the SBI example and labels what they're doing ('I'll use a concrete moment, name only what a camera could capture, and own the impact') but doesn't explain WHY they made specific choices like why 'started talking while I was mid-sentence' is better than alternatives."
              },
              "B-03": {
                "verdict": "FAIL",
                "evidence": "Mentor presents the model without showing any deliberation or alternatives considered. No moments like 'I could say X but instead I chose Y because...' The example is presented as a finished product."
              },
              "B-04": {
                "verdict": "PASS",
                "evidence": "Mentor explicitly models self-checking: 'My self-check: can I picture the moment, would a camera catch those words/actions, and is the impact something I felt or did.'"
              },
              "B-05": {
                "verdict": "PASS",
                "evidence": "Mentor offers multiple reusable heuristics: 'the camera test' (referenced throughout), 'If you hear yourself saying \"made me look\u2026\" or \"they were\u2026,\" swap to \"I felt X, and I couldn't Y\"' and the three-part self-check (moment, camera, owned)."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 2,
              "pass_rate": 0.5,
              "failed_criteria": [
                "B-02",
                "B-03"
              ]
            },
            "_metadata": {
              "judge_id": "modeling_quality",
              "conversation_id": "e2206591",
              "evaluated_at": "2026-01-21T10:48:47.122983"
            }
          }
        },
        "coaching_quality": {
          "passed": 5,
          "total": 5,
          "json": {
            "criteria": {
              "C-02": {
                "verdict": "PASS",
                "evidence": "Mentor consistently provides actionable direction. Example: 'Replace \"design reviews lately\" with a single, named moment\u2014e.g., \"In Thursday's design review\"\u2014and re-send your opening line with that anchor.' Also: 'swap the labels (\"dismissive,\" \"brushing off\") for the exact words you heard in that moment\u2014write one sentence that captures what they said while you were mid-sentence.'"
              },
              "C-04": {
                "verdict": "PASS",
                "evidence": "Mentor evaluates revisions specifically. Example: 'That's camera-testable\u2014nice.' After full revision: 'That lands\u2014the moment is concrete, the behavior's camera-testable, and the impact is owned.' Also: 'What works: your behavior line is concrete and camera-testable. Where it misses: the impact isn't owned...'"
              },
              "C-05": {
                "verdict": "PASS",
                "evidence": "Mentor explores errors before correcting. When learner says 'dismissive' is camera-testable, mentor asks: 'If you couldn't use the label \"dismissive,\" what exact words or actions from that moment would you name instead?' Also asks 'Before I weigh in, where do you think I'll push back on your draft?' and 'Run the self-check on your draft\u2014moment, camera, owned\u2014and tell me which parts pass and which need revision.'"
              },
              "C-06": {
                "verdict": "PASS",
                "evidence": "Mentor asks learner to explain reasoning behind SBI choices. Example: 'You chose \"I felt cut off and lost my train of thought\"\u2014what were you trying to capture with that impact?' Learner responds by articulating their reasoning about personal experience and immediate effects."
              },
              "C-07": {
                "verdict": "PASS",
                "evidence": "Mentor prompts reflection on learning process. Example: 'Stepping back: what was the hardest part for you to pin down here, and why?' Learner reflects: 'Turning my interpretation into exact words was the hardest\u2014replacing labels like \"dismissive\" with what they actually said.' Also asks 'What's one principle you'll carry forward to keep the impact owned rather than slipping into judgments?'"
              }
            },
            "overall": {
              "passed_count": 5,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "coaching_quality",
              "conversation_id": "e2206591",
              "evaluated_at": "2026-01-21T10:49:01.844538"
            }
          }
        },
        "sbi_content": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "D-04": {
                "verdict": "PASS",
                "evidence": "Mentor asks 'If you couldn't use the label \"dismissive,\" what exact words or actions from that moment would you name instead?' and 'Pick one moment from that review and rewrite \"brushing off my points\" as something a camera could catch\u2014what exact words did they say while you were speaking?' These questions probe whether the learner can distinguish between interpretive labels and observable actions."
              },
              "D-05": {
                "verdict": "PASS",
                "evidence": "When learner struggled to convert interpretations to observations, mentor provided targeted scaffolding: 'Pick one moment from that review and rewrite \"brushing off my points\" as something a camera could catch\u2014what exact words did they say while you were speaking?' Also provided specific guidance on impact: 'Rewrite the impact so it names what you felt or exactly what you couldn't do in that moment.'"
              },
              "D-06": {
                "verdict": "PASS",
                "evidence": "Mentor provides multiple reusable tools: (1) the 'camera test' for behavior ('would a camera capture that'), (2) the self-check framework 'moment, camera, owned', (3) the sentence stem 'I felt X, and I couldn't Y' for owned impact, and (4) the swap rule 'if you hear yourself saying \"made me look\u2026\" or \"they were\u2026,\" swap to \"I felt X, and I couldn't Y\"'"
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "sbi_content",
              "conversation_id": "e2206591",
              "evaluated_at": "2026-01-21T10:49:15.309819"
            }
          }
        },
        "adaptive_pacing": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "E-01": {
                "verdict": "PASS",
                "evidence": "Mentor checks readiness multiple times: 'Ready to dive in?', 'Ready for a full attempt?', 'Can you draft that line now?', 'Can you write that now?', 'Anything else you want to tune before you take it into your 1:1?'"
              },
              "E-02": {
                "verdict": "PASS",
                "evidence": "Early on, mentor provides detailed scaffolding and stems. After learner demonstrates competence with first full SBI, mentor gives second scenario with minimal guidance ('Write the full message...Share your complete draft') and shifts to asking learner to self-identify issues ('Before I weigh in, where do you think I'll push back?'). By end, mentor simply confirms learner's self-generated rule rather than providing structure."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "adaptive_pacing",
              "conversation_id": "e2206591",
              "evaluated_at": "2026-01-21T10:49:27.196442"
            }
          }
        },
        "conversational_quality": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "F-01": {
                "verdict": "PASS",
                "evidence": "Turn structure varies: short reactions ('Nice catch', 'That's camera-testable\u2014nice', 'Good anchor'), longer explanations with examples, focused questions ('what exact words did they say'), and reflective prompts ('what was the hardest part for you'). Some turns are single sentences, others are multi-part instructions."
              },
              "F-02": {
                "verdict": "PASS",
                "evidence": "Mentor shows personality through casual affirmations ('Nice catch', 'That lands', 'You've got it'), emoji use ('\ud83d\udc4d' appears multiple times), and conversational phrases like 'Go put it to work' and 'Keep that self-check in your pocket.' Not purely neutral facilitation."
              },
              "F-03": {
                "verdict": "N/A",
                "evidence": "Learner never displays anxiety, frustration, or confusion throughout the transcript. They respond cooperatively and confidently, even when corrected. No negative affect to respond to."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "na_count": 1,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "conversational_quality",
              "conversation_id": "e2206591",
              "evaluated_at": "2026-01-21T10:49:39.732182"
            }
          }
        }
      }
    },
    {
      "langsmith_id": "79a3706b-e830-4f96-91fd-55dc6eca32d5",
      "short_id": "79a3706b",
      "source_type": "dataset",
      "critical_verdict": "PASS",
      "critical_json": null,
      "quality_results": {
        "session_setup": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "A-01": {
                "verdict": "PASS",
                "evidence": "Mentor states: 'We're going to work on delivering peer feedback using the SBI framework. Success means you anchor to a specific moment, describe only what was observable, and name the impact in your own terms\u2014and we'll also watch for judgment sneaking into the behavior.'"
              },
              "A-02": {
                "verdict": "PASS",
                "evidence": "Mentor explicitly signals phase transition: 'I'll demonstrate first so you can see how I think it through\u2014ready to dive in?' and later 'Here's a quick demo and how I'm thinking' followed by 'Does that clear it up enough to do a quick check before you try your own?'"
              },
              "A-03": {
                "verdict": "PASS",
                "evidence": "Multiple realistic workplace scenarios used: Tuesday's standup with interruption during update, last Thursday's 9:30 a.m. standup with vendor issue, and Tuesday's sprint review with Director on call where PM talks over test coverage update\u2014all feature specific meetings, plausible interpersonal dynamics, and believable workplace tensions."
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "session_setup",
              "conversation_id": "79a3706b",
              "evaluated_at": "2026-01-21T10:50:07.488176"
            }
          }
        },
        "modeling_quality": {
          "passed": 3,
          "total": 4,
          "json": {
            "criteria": {
              "B-02": {
                "verdict": "PASS",
                "evidence": "Mentor explains reasoning: 'For behavior, I avoid labels like \"you interrupted\" and stick to what a camera would catch: who spoke when. For impact, I use my own experience and consequence, not a judgment.'"
              },
              "B-03": {
                "verdict": "PASS",
                "evidence": "Mentor shows choice point: 'I avoid labels like \"you interrupted\" and stick to what a camera would catch' - explicitly contrasting a rejected option with the chosen approach."
              },
              "B-04": {
                "verdict": "FAIL",
                "evidence": "Mentor does not model checking their own example against criteria. They teach the learner to self-check but don't demonstrate self-verification on their own model."
              },
              "B-05": {
                "verdict": "PASS",
                "evidence": "Mentor offers 'the camera test' heuristic: 'what a camera would catch' and later reinforces 'If a word judges or blames (e.g., \"dismissive,\" \"hijacked,\" \"made me\"), rewrite it into exact words/actions or \"I felt\u2026/so I\u2026\"'"
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 1,
              "pass_rate": 0.75,
              "failed_criteria": [
                "B-04"
              ]
            },
            "_metadata": {
              "judge_id": "modeling_quality",
              "conversation_id": "79a3706b",
              "evaluated_at": "2026-01-21T10:50:18.849726"
            }
          }
        },
        "coaching_quality": {
          "passed": 5,
          "total": 5,
          "json": {
            "criteria": {
              "C-02": {
                "verdict": "PASS",
                "evidence": "Mentor consistently provides actionable direction. Example: 'The judgment leak is \"dismissive\"\u2014what did you actually see or hear in that moment (e.g., exact words, interruptions, gestures) that you could name instead?' and 'swap it for owned impact: name your feelings (you said uncomfortable and rushed) plus the concrete consequence you already had (needing to follow up in Slack), all in one sentence.'"
              },
              "C-04": {
                "verdict": "PASS",
                "evidence": "Mentor evaluates revisions specifically. Example: After learner revises to 'You said, \"This proposal isn't realistic,\" while keeping your eyes on your laptop and continuing to type,' mentor moves forward implicitly accepting. More explicitly, after the final revision: 'That lands\u2014clear moment, camera-test behavior, and fully owned impact. You're meeting the bar.'"
              },
              "C-05": {
                "verdict": "PASS",
                "evidence": "Mentor explores errors before correcting. Example: 'Before I weigh in, where do you expect me to push back on this?' and 'Run the 3-check on your draft\u2014specific moment, camera-test behavior, owned impact\u2014what, if anything, doesn't meet those?' Also: 'One phrase I'm curious about is \"made the meeting awkward\"\u2014what were you trying to convey with that wording?'"
              },
              "C-06": {
                "verdict": "PASS",
                "evidence": "Mentor asks learner to explain reasoning behind choices. Example: 'One phrase I'm curious about is \"made the meeting awkward\"\u2014what were you trying to convey with that wording?' This asks the learner to articulate their thinking behind a specific word choice."
              },
              "C-07": {
                "verdict": "PASS",
                "evidence": "Mentor prompts reflection at the end: 'What's one principle you'll carry forward to keep your next SBI this tight?' This asks the learner to step back and identify a transferable learning principle."
              }
            },
            "overall": {
              "passed_count": 5,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "coaching_quality",
              "conversation_id": "79a3706b",
              "evaluated_at": "2026-01-21T10:50:34.775076"
            }
          }
        },
        "sbi_content": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "D-04": {
                "verdict": "PASS",
                "evidence": "Mentor asks 'what did you actually see or hear in that moment (e.g., exact words, interruptions, gestures) that you could name instead?' when learner doesn't recognize 'dismissive' as judgment. Also probes 'made the meeting awkward' asking 'what were you trying to convey with that wording?' to test if learner understands the observable vs. interpretive distinction."
              },
              "D-05": {
                "verdict": "PASS",
                "evidence": "When learner struggles with rewriting behavior, mentor offers targeted scaffolding: 'Try rewriting the behavior as one sentence the camera would catch\u2014use the exact words plus a specific nonverbal.' Also provides specific guidance: 'Try starting with \"I felt\u2026\" and give me that one sentence' when learner writes 'You made me feel...'"
              },
              "D-06": {
                "verdict": "PASS",
                "evidence": "Mentor provides the 'camera test' as a reusable tool multiple times ('what a camera would catch,' 'camera-test behavior'). Also gives the '3-check' framework: 'Run the 3-check on your draft\u2014specific moment, camera-test behavior, owned impact.' Learner explicitly takes away: 'Use the camera test for behavior\u2014stick to exact words/actions, not labels.'"
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "sbi_content",
              "conversation_id": "79a3706b",
              "evaluated_at": "2026-01-21T10:50:47.167059"
            }
          }
        },
        "adaptive_pacing": {
          "passed": 1,
          "total": 2,
          "json": {
            "criteria": {
              "E-01": {
                "verdict": "PASS",
                "evidence": "Mentor checks readiness multiple times: 'What stood out or feels unclear before we do a quick check?', 'Does that clear it up enough to do a quick check before you try your own?', 'Before I weigh in, where do you expect me to push back on this?'"
              },
              "E-02": {
                "verdict": "FAIL",
                "evidence": "Mentor provides consistent scaffolding throughout - continues offering detailed guidance, specific corrections, and checking work even after learner demonstrates competence (e.g., still providing detailed feedback on the final scenario after learner successfully completed earlier SBI). No visible reduction in support level."
              }
            },
            "overall": {
              "passed_count": 1,
              "failed_count": 1,
              "pass_rate": 0.5,
              "failed_criteria": [
                "E-02"
              ]
            },
            "_metadata": {
              "judge_id": "adaptive_pacing",
              "conversation_id": "79a3706b",
              "evaluated_at": "2026-01-21T10:50:57.600424"
            }
          }
        },
        "conversational_quality": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "F-01": {
                "verdict": "PASS",
                "evidence": "Turn structure varies: short affirmations ('That lands\u2014your first attempt meets the bar \ud83d\udc4d'), longer explanations with examples (demo turn), direct questions ('Which single meeting are you choosing?'), metacognitive prompts ('Before I weigh in, where do you expect me to push back?'), and concise corrections ('Direct feedback: your anchor misses the mark')."
              },
              "F-02": {
                "verdict": "PASS",
                "evidence": "Shows personality through reactions like 'Good eye on the camera test,' 'Nice tightening,' emoji use ('\ud83d\udc4d'), and phrases like 'I'm curious about' when probing\u2014not purely neutral facilitation."
              },
              "F-03": {
                "verdict": "N/A",
                "evidence": "Learner never displays anxiety, frustration, or confusion. They remain confident throughout, even when incorrect ('I think it's fine as written,' 'I think it mostly works as is')."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "na_count": 1,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "conversational_quality",
              "conversation_id": "79a3706b",
              "evaluated_at": "2026-01-21T10:51:09.759985"
            }
          }
        }
      }
    },
    {
      "langsmith_id": "df150be8-b097-4dbd-a753-f1ad6aa991bc",
      "short_id": "df150be8",
      "source_type": "dataset",
      "critical_verdict": "PASS",
      "critical_json": {
        "criteria": {
          "B-01": {
            "verdict": "PASS",
            "evidence": "Mentor demonstrates complete SBI: 'Imagine Tuesday's standup: after I said \"the integration test failed again,\" Jordan cut in mid-sentence and spoke over me twice; I anchor to that moment, then name only what a camera would catch\u2014\"you jumped in with questions and spoke over me twice while I was still answering\"... For impact, I keep it owned and immediate: \"I lost my train of thought, felt flustered, and skipped two updates; I had to follow up afterward in DMs.\"'"
          },
          "C-01": {
            "verdict": "PASS",
            "evidence": "Mentor quotes specific problematic language: '\"dismissive,\" \"didn't seem to respect my role,\" and \"took over the conversation\" aren't camera\u2011testable' and 'your line talks about the meeting and the team, not you' and '\"It felt unprofessional\" is a judgment, and \"you made the client uncomfortable\" is mind\u2011reading.'"
          },
          "C-03": {
            "verdict": "PASS",
            "evidence": "Mentor repeatedly requests revisions: 'Replace those with only what you saw/heard... Keep the situation the same and resend your full 2\u20133 sentences with that behavior tightened.' and 'Revise the impact to name your felt state or a direct consequence you personally dealt with, then resend your full 2\u20133 sentences.'"
          },
          "D-01": {
            "verdict": "PASS",
            "evidence": "When learner wrote 'In our standups lately,' mentor caught it: 'Got it\u2014patterns happen, but for SBI we need one concrete instance. Can you pick one specific standup (say yesterday's or Tuesday's)' and later 'First gap: it's not anchored to one identifiable moment\u2014\"Lately\u2026 including the Acme one\" diffuses it.'"
          },
          "D-02": {
            "verdict": "PASS",
            "evidence": "Mentor catches judgment words multiple times: 'Are the behaviors camera-testable (no motives like \"dismissive,\" just what was said/done)?' and 'The behavior line still carries judgment/inference: \"dismissive,\" \"didn't seem to respect my role,\" and \"took over the conversation\" aren't camera\u2011testable.'"
          },
          "D-03": {
            "verdict": "PASS",
            "evidence": "When learner wrote 'You made the meeting awkward and caused confusion for the team' and 'you made the client uncomfortable,' mentor caught it: 'This is the spot that trips people up\u2014your line talks about the meeting and the team, not you' and '\"you made the client uncomfortable\" is mind\u2011reading.'"
          },
          "E-03": {
            "verdict": "PASS",
            "evidence": "When learner said 'I think it's mostly fine,' mentor didn't give the answer but prompted self-evaluation: 'Let's run a quick self-check\u2014answer yes/no for each: 1) Is it anchored to one identifiable standup... What do you get for each, and where's the first \"no\"?' Also asked 'Before I weigh in, predict where I'll push back.'"
          }
        },
        "overall": {
          "verdict": "PASS",
          "summary": "The mentor demonstrates all critical tutoring behaviors: modeling a complete SBI example, providing specific feedback with quoted language, requesting revisions, catching vague situations and judgment leakage and accusatory impact, and protecting productive struggle by requiring learner self-evaluation before providing answers.",
          "passed_count": 7,
          "failed_count": 0,
          "na_count": 0,
          "failed_criteria": []
        },
        "_metadata": {
          "judge_id": "critical_criteria",
          "conversation_id": "df150be8",
          "evaluated_at": "2026-01-21T10:51:28.513987"
        }
      },
      "quality_results": {
        "session_setup": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "A-01": {
                "verdict": "PASS",
                "evidence": "Mentor states: 'We're working on delivering peer feedback using the SBI framework. Success means you anchor to a specific moment, describe observable behavior, use owned impact language, and can spot where judgment creeps in.'"
              },
              "A-02": {
                "verdict": "PASS",
                "evidence": "Mentor explicitly signals phase transition: 'I'll model my approach first, then you'll try\u2014ready to begin?' and later 'I'll pause there\u2014ready to take a swing with a real moment from your world?'"
              },
              "A-03": {
                "verdict": "PASS",
                "evidence": "Multiple realistic scenarios used: standup interruption with Jordan, client kickoff with manager Priya at Acme on Zoom in front of Sales, and Slack thread with Sam replying 'this feels alarmist' with emoji\u2014all contain specific interpersonal dynamics and plausible workplace contexts."
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "session_setup",
              "conversation_id": "df150be8",
              "evaluated_at": "2026-01-21T10:51:37.859224"
            }
          }
        },
        "modeling_quality": {
          "passed": 3,
          "total": 4,
          "json": {
            "criteria": {
              "B-02": {
                "verdict": "PASS",
                "evidence": "Mentor explains reasoning: \"I anchor to that moment, then name only what a camera would catch\u2014'you jumped in with questions and spoke over me twice while I was still answering,' not 'you dismissed me.'\" and \"The key decisions: pick one recognizable moment, strip out motives/adjectives, and keep the impact in my body or workload\u2014not a judgment like 'it was unprofessional.'\""
              },
              "B-03": {
                "verdict": "PASS",
                "evidence": "Mentor shows a choice point with alternatives: \"name only what a camera would catch\u2014'you jumped in with questions and spoke over me twice while I was still answering,' not 'you dismissed me.'\" This explicitly contrasts what they chose vs. what they rejected."
              },
              "B-04": {
                "verdict": "FAIL",
                "evidence": "During the initial modeling, the mentor does not demonstrate checking their own work against criteria. They present the model without saying something like 'Let me test this...' The self-checking prompts later are directed at the learner's work, not the mentor's own demonstration."
              },
              "B-05": {
                "verdict": "PASS",
                "evidence": "Mentor offers reusable heuristics: \"name only what a camera would catch\" (camera test), \"pick one recognizable moment, strip out motives/adjectives, and keep the impact in my body or workload.\" Later reinforced with \"if a neutral observer could verify the behavior and you can start the impact with 'I\u2026,' you're in bounds.\""
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 1,
              "pass_rate": 0.75,
              "failed_criteria": [
                "B-04"
              ]
            },
            "_metadata": {
              "judge_id": "modeling_quality",
              "conversation_id": "df150be8",
              "evaluated_at": "2026-01-21T10:51:50.356815"
            }
          }
        },
        "coaching_quality": {
          "passed": 5,
          "total": 5,
          "json": {
            "criteria": {
              "C-02": {
                "verdict": "PASS",
                "evidence": "Mentor provides actionable direction multiple times, e.g., 'Swap \"dismissive\"/\"took over\" for concrete actions: you cut in while I was mid\u2011sentence, spoke over me twice, then presented your plan for a few minutes, and I didn't finish my update.'"
              },
              "C-04": {
                "verdict": "PASS",
                "evidence": "Mentor evaluates revisions specifically, e.g., 'Anchor and behavior are on target. Impact misses: \"It felt unprofessional\" is a judgment, and \"you made the client uncomfortable\" is mind\u2011reading.' Also: 'That meets the bar\u2014anchored to a specific kickoff, observable behavior only, and owned impact.'"
              },
              "C-05": {
                "verdict": "PASS",
                "evidence": "Mentor explores errors before correcting, e.g., 'Before I give feedback, where do you think this misses our criteria\u2014specific moment, camera-test behavior, or owned impact?' and 'Let's run a quick self-check\u2014answer yes/no for each...'"
              },
              "C-06": {
                "verdict": "PASS",
                "evidence": "Mentor asks learner to explain reasoning: 'Walk me through \"took over the conversation\"\u2014what concrete action are you trying to capture there that a camera would show?'"
              },
              "C-07": {
                "verdict": "PASS",
                "evidence": "Mentor prompts reflection on learning: 'What, if anything, was the hardest part to write here?' and 'What's the one principle you'll carry forward to keep judgment and mind\u2011reading out of your behavior and impact lines, especially when the stakes are high?'"
              }
            },
            "overall": {
              "passed_count": 5,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "coaching_quality",
              "conversation_id": "df150be8",
              "evaluated_at": "2026-01-21T10:52:02.355002"
            }
          }
        },
        "sbi_content": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "D-04": {
                "verdict": "PASS",
                "evidence": "Mentor asks 'which exact words in your draft aren't camera-testable or aren't owned impact\u2014call them out explicitly' and later 'Walk me through \"took over the conversation\"\u2014what concrete action are you trying to capture there that a camera would show?' These probe whether learner understands the observable vs. interpretive distinction."
              },
              "D-05": {
                "verdict": "PASS",
                "evidence": "When learner struggled with impact line, mentor provided targeted scaffolding: 'put it in one sentence that starts with \"I \u2026\"?' Also provided specific sentence stems and partial answers: 'Swap \"dismissive\"/\"took over\" for concrete actions: you cut in while I was mid\u2011sentence, spoke over me twice, then presented your plan for a few minutes...'"
              },
              "D-06": {
                "verdict": "PASS",
                "evidence": "Mentor provides the 'camera/I test' as a reusable tool: 'use your \"camera/I\" test as a quick gate before you speak or send: if a neutral observer could verify the behavior and you can start the impact with \"I\u2026,\" you're in bounds; if not, swap intent words for verbs or name a personal consequence instead.'"
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "sbi_content",
              "conversation_id": "df150be8",
              "evaluated_at": "2026-01-21T10:52:14.532167"
            }
          }
        },
        "adaptive_pacing": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "E-01": {
                "verdict": "PASS",
                "evidence": "Mentor checks readiness multiple times: 'ready to begin?', 'ready to take a swing with a real moment from your world?', 'Want one last lightning rep to lock it in, or wrap here?'"
              },
              "E-02": {
                "verdict": "PASS",
                "evidence": "Early on, mentor provides detailed self-check questions (yes/no for each criterion) and explicit stems. By the second scenario, mentor gives briefer feedback ('Anchor's solid... Impact misses') without re-explaining the full framework. By lightning rep, mentor simply says 'Draft your 2\u20133 sentence SBI' with no scaffolding stems or guided questions."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "adaptive_pacing",
              "conversation_id": "df150be8",
              "evaluated_at": "2026-01-21T10:52:24.384004"
            }
          }
        },
        "conversational_quality": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "F-01": {
                "verdict": "PASS",
                "evidence": "Turns vary from longer explanations (initial modeling), to short affirmations ('Good catch on all three', 'Nice\u2014', 'That lands'), to focused questions ('Which one is it?'), to structured self-check prompts (yes/no checklist), to brief wrap-ups ('You've got it\u2014carry that forward \ud83d\udc4d')"
              },
              "F-02": {
                "verdict": "PASS",
                "evidence": "Shows personality through reactions like 'Good eye on those two', 'Nice\u2014', 'That lands\u2014you're ready to use it in the wild', thumbs up emoji '\ud83d\udc4d', and casual phrasing like 'take a swing with a real moment from your world'"
              },
              "F-03": {
                "verdict": "N/A",
                "evidence": "Learner never displays anxiety, frustration, or confusion\u2014they engage cooperatively throughout, acknowledge gaps when prompted, and express readiness ('Yep, I'm ready', 'Got it', 'One last lightning rep works')"
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "na_count": 1,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "conversational_quality",
              "conversation_id": "df150be8",
              "evaluated_at": "2026-01-21T10:52:36.419317"
            }
          }
        }
      }
    },
    {
      "langsmith_id": "de804a3e-d79d-4032-ba30-d16db7fa53ea",
      "short_id": "de804a3e",
      "source_type": "dataset",
      "critical_verdict": "PASS",
      "critical_json": null,
      "quality_results": {
        "session_setup": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "A-01": {
                "verdict": "PASS",
                "evidence": "Mentor states: 'We're working on delivering peer feedback using SBI. Success means you anchor to a real moment, name only observable behavior, and own your actual impact.'"
              },
              "A-02": {
                "verdict": "PASS",
                "evidence": "Mentor explicitly signals transitions: 'I'll demonstrate how I approach it first\u2014ready to see a quick example?' and later 'What did you notice in that example before we shift to your turn?' and 'Now it's your turn to practice' equivalent: 'Your turn.'"
              },
              "A-03": {
                "verdict": "PASS",
                "evidence": "The scenarios involve specific workplace situations: 'Weekly Team Sync on Monday at 2pm' with details about being interrupted during updates, and 'last Thursday's quarterly planning review with the VP' involving Jordan from Sales\u2014both include plausible interpersonal dynamics around meeting interruptions and topic derailing."
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "session_setup",
              "conversation_id": "de804a3e",
              "evaluated_at": "2026-01-21T10:53:03.230408"
            }
          }
        },
        "modeling_quality": {
          "passed": 4,
          "total": 4,
          "json": {
            "criteria": {
              "B-02": {
                "verdict": "PASS",
                "evidence": "\"I'm anchoring to one meeting, naming only what a camera would catch, and owning my reaction instead of labeling it 'rude'\u2014I'm watching for judgment-creep words.\" The mentor explains WHY they made each choice during the demonstration."
              },
              "B-03": {
                "verdict": "PASS",
                "evidence": "\"owning my reaction instead of labeling it 'rude'\" - The mentor shows a choice point where they considered an alternative (calling it 'rude') but chose observable behavior instead."
              },
              "B-04": {
                "verdict": "PASS",
                "evidence": "The mentor models self-checking by stating \"I'm anchoring to one meeting, naming only what a camera would catch\" - explicitly verifying their work against the SBI criteria during the demonstration."
              },
              "B-05": {
                "verdict": "PASS",
                "evidence": "\"camera + I\" check is offered as a reusable heuristic: \"run a quick 'camera + I' check\u2014one calendar moment, only filmable actions (swap labels for quotes/counts), and an impact that starts with 'I'\""
              }
            },
            "overall": {
              "passed_count": 4,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "modeling_quality",
              "conversation_id": "de804a3e",
              "evaluated_at": "2026-01-21T10:53:13.794480"
            }
          }
        },
        "coaching_quality": {
          "passed": 5,
          "total": 5,
          "json": {
            "criteria": {
              "C-02": {
                "verdict": "PASS",
                "evidence": "Mentor provides actionable direction multiple times. Example: 'Tone tweaks can wait; first we need a solid anchor. Pick one real moment to ground it\u2014what specific meeting would you name?' and 'Replace that with how it hit you in the moment\u2014your feeling or a direct consequence for you\u2014and send the full 2\u20133 sentences again.'"
              },
              "C-04": {
                "verdict": "PASS",
                "evidence": "Mentor evaluates revisions specifically. Example: After learner's revision, mentor says 'This mostly lands. One small tighten: \"asking the team to move on\" reads like interpretation unless those were the exact words\u2014can you swap in the precise quote or just drop that clause?' and later 'That lands\u2014you met all three criteria: solid anchor, camera\u2011testable behavior, and owned impact.'"
              },
              "C-05": {
                "verdict": "PASS",
                "evidence": "Mentor explores errors before correcting. When learner says draft is 'mostly fine,' mentor asks 'where do you think I'll push back\u2014what in your draft isn't camera-testable or slips into judgment?' and provides a self-check framework rather than immediately correcting."
              },
              "C-06": {
                "verdict": "PASS",
                "evidence": "Mentor asks learner to explain reasoning: 'Walk me through your behavior phrasing\u2014\"talking over me twice\" and the \"let's get back to sprint goals\" quote\u2014what were you trying to capture with those choices?'"
              },
              "C-07": {
                "verdict": "PASS",
                "evidence": "Mentor prompts reflection on learning: 'What principle from this will you carry forward when you give SBI in the wild?' This asks learner to step back and identify transferable learning."
              }
            },
            "overall": {
              "passed_count": 5,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "coaching_quality",
              "conversation_id": "de804a3e",
              "evaluated_at": "2026-01-21T10:53:27.171109"
            }
          }
        },
        "sbi_content": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "D-04": {
                "verdict": "PASS",
                "evidence": "Mentor asks 'where do you think I'll push back\u2014what in your draft isn't camera-testable or slips into judgment?' and provides a self-check asking learner to identify what 'behaviors a camera/mic would capture (no labels like \"dismissive,\" \"derailing,\" \"undermined\")' - probing the observable vs. interpretive distinction."
              },
              "D-05": {
                "verdict": "PASS",
                "evidence": "When learner struggled to identify a specific meeting, mentor scaffolded with 'What's one specific meeting on your calendar where this happened\u2014the last time is fine; what was it called?' When learner couldn't self-identify issues, mentor provided a structured 3-part self-check tool to work through systematically."
              },
              "D-06": {
                "verdict": "PASS",
                "evidence": "Mentor explicitly provides the 'camera + I' check as a reusable tool: 'run a quick \"camera + I\" check\u2014one calendar moment, only filmable actions (swap labels for quotes/counts), and an impact that starts with \"I\"; if any part wobbles, tighten before you deliver.' Learner confirms they'll use this independently."
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "sbi_content",
              "conversation_id": "de804a3e",
              "evaluated_at": "2026-01-21T10:53:39.818299"
            }
          }
        },
        "adaptive_pacing": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "E-01": {
                "verdict": "PASS",
                "evidence": "Mentor checks readiness multiple times: 'ready to see a quick example?', 'What did you notice in that example before we shift to your turn?', 'Quick check before we shift to your draft', 'Anything else you want to lock in before you try it?'"
              },
              "E-02": {
                "verdict": "PASS",
                "evidence": "Early on, mentor provides detailed self-check criteria and walks through each component. By round two, mentor gives minimal guidance ('The gap is impact...Replace that with how it hit you'). By the pattern add-on, mentor only offers 'micro-tighten if you want it' and asks 'Keep yours or swap in that tweak\u2014what feels more natural in your voice?' showing reduced scaffolding as learner demonstrates competence."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "adaptive_pacing",
              "conversation_id": "de804a3e",
              "evaluated_at": "2026-01-21T10:53:50.039813"
            }
          }
        },
        "conversational_quality": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "F-01": {
                "verdict": "PASS",
                "evidence": "Turn structure varies: short affirmations ('That lands\u2014you hit all three criteria \ud83d\udc4d'), longer explanations with multiple components, questions ('What did you notice in that example?'), micro-edit requests ('Make that micro-edit and share your tweaked 2\u20133 sentences'), and closing turns that invite reflection ('What principle from this will you carry forward?')"
              },
              "F-02": {
                "verdict": "PASS",
                "evidence": "Mentor shows personality through casual reactions ('Good questions'), thumbs up emoji usage ('\ud83d\udc4d'), phrases like 'go make it happen,' 'You've got a reliable \"camera + I\" muscle now,' and the conversational closing 'I'll be here when you want a quick check'"
              },
              "F-03": {
                "verdict": "N/A",
                "evidence": "Learner does not display anxiety, frustration, or confusion throughout the transcript. They engage cooperatively, ask clarifying questions, and respond positively to corrections without emotional distress."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "na_count": 1,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "conversational_quality",
              "conversation_id": "de804a3e",
              "evaluated_at": "2026-01-21T10:54:02.684883"
            }
          }
        }
      }
    },
    {
      "langsmith_id": "91f1f846-6b17-4ca0-a258-d5892fc44b2d",
      "short_id": "91f1f846",
      "source_type": "dataset",
      "critical_verdict": "PASS",
      "critical_json": {
        "criteria": {
          "B-01": {
            "verdict": "PASS",
            "evidence": "Mentor demonstrates complete SBI example: '1) Situation: \"In Tuesday's standup when I was sharing blockers\u2026\" 2) Behavior: \"\u2026you jumped in twice before I finished\u2014first right after I mentioned the vendor delay, and again as I started to explain the workaround.\" 3) Impact: \"I felt flustered and lost my train of thought, and I left out a key dependency, so I had to follow up after the meeting.\"'"
          },
          "C-01": {
            "verdict": "PASS",
            "evidence": "Mentor points to exact language: 'The situation is too vague\u2014\"in our recent go/no\u2011go meetings\" misses the single\u2011moment test.' Also earlier guided learner to self-identify issues with specific phrases like 'pretty dismissive' and 'in our standups lately.'"
          },
          "C-03": {
            "verdict": "PASS",
            "evidence": "After feedback on second draft, mentor explicitly requests revision: 'Keep the concrete chat quote, but anchor to last Thursday's 4 p.m. go/no\u2011go and resend your full draft\u2014can you revise with that specific moment?'"
          },
          "D-01": {
            "verdict": "PASS",
            "evidence": "When learner wrote 'in our standups lately' and 'in our recent go/no-go meetings,' mentor caught both: 'If it's a pattern, what's one specific standup that captures it that you could name so it stays concrete?' and 'The situation is too vague\u2014\"in our recent go/no\u2011go meetings\" misses the single\u2011moment test.'"
          },
          "D-02": {
            "verdict": "PASS",
            "evidence": "When learner used 'pretty dismissive' in behavior, mentor guided learner to self-identify via the self-check tool. Learner recognized: '\"Pretty dismissive\" isn't camera-capturable. Tweak: \"you interrupted me twice...\"' Mentor validated this correction."
          },
          "D-03": {
            "verdict": "PASS",
            "evidence": "When learner wrote 'It made the meeting awkward and created tension for the team,' mentor guided learner through self-check. Learner identified: '\"Made the meeting awkward\"/\"tension for the team\" isn't owned. Tweak: \"I felt flustered and lost my place...\"' Mentor validated this correction."
          },
          "E-03": {
            "verdict": "PASS",
            "evidence": "When learner said 'I think it's mostly fine as is,' mentor didn't give the answer but required learner to work through it: 'Let's stress-test it with the S-B-I self-check. Ask yourself... Tell me what (if anything) doesn't pass and how you'd tweak those bits.'"
          }
        },
        "overall": {
          "verdict": "PASS",
          "summary": "The mentor demonstrated a complete SBI example, provided specific feedback referencing exact language, requested revisions, caught all error types (vague situations, judgment leakage, accusatory impact), and protected productive struggle by requiring learner attempts.",
          "passed_count": 7,
          "failed_count": 0,
          "na_count": 0,
          "failed_criteria": []
        },
        "_metadata": {
          "judge_id": "critical_criteria",
          "conversation_id": "91f1f846",
          "evaluated_at": "2026-01-21T10:54:21.538680"
        }
      },
      "quality_results": {
        "session_setup": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "A-01": {
                "verdict": "PASS",
                "evidence": "Mentor states: 'We'll work on delivering peer feedback using the Situation-Behavior-Impact framework. Success means anchoring to a real moment, describing observable behavior, and owning the impact\u2014while noticing when judgment sneaks into the behavior.'"
              },
              "A-02": {
                "verdict": "PASS",
                "evidence": "Mentor explicitly signals phase transition: 'I'll demo my process first, then we'll move to yours\u2014ready to begin?' and later 'Second rep\u2014higher stakes, different peer...'"
              },
              "A-03": {
                "verdict": "PASS",
                "evidence": "The scenarios involve realistic workplace situations: a standup meeting about UAT bug backlog with a colleague interrupting, and a cross-functional release go/no-go meeting with a Payments PM (Maya) cutting in during a rollback plan presentation to leadership\u2014both with specific, plausible interpersonal dynamics."
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "session_setup",
              "conversation_id": "91f1f846",
              "evaluated_at": "2026-01-21T10:54:31.777814"
            }
          }
        },
        "modeling_quality": {
          "passed": 4,
          "total": 4,
          "json": {
            "criteria": {
              "B-02": {
                "verdict": "PASS",
                "evidence": "Mentor explains: 'Why these choices: I anchor to a specific meeting; I keep behavior camera-testable (counts and moments, not intent words like \"dismissive\"); I own the impact (my feeling and concrete consequence), not a verdict like \"that was unprofessional.\"'"
              },
              "B-03": {
                "verdict": "PASS",
                "evidence": "Mentor shows a choice point: 'I keep behavior camera-testable (counts and moments, not intent words like \"dismissive\")' - explicitly contrasting what they chose vs. what they rejected."
              },
              "B-04": {
                "verdict": "PASS",
                "evidence": "Mentor models self-checking: 'Self-check tool you can reuse: S = calendar moment; B = camera could see/hear it; I = inside-my-skin feeling or direct consequence for me/my work. Strip judgment words.'"
              },
              "B-05": {
                "verdict": "PASS",
                "evidence": "Mentor provides reusable heuristics: 'S = calendar moment; B = camera could see/hear it; I = inside-my-skin feeling or direct consequence' and 'Strip judgment words' - generalizable rules the learner can apply independently."
              }
            },
            "overall": {
              "passed_count": 4,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "modeling_quality",
              "conversation_id": "91f1f846",
              "evaluated_at": "2026-01-21T10:54:42.019425"
            }
          }
        },
        "coaching_quality": {
          "passed": 5,
          "total": 5,
          "json": {
            "criteria": {
              "C-02": {
                "verdict": "PASS",
                "evidence": "When learner's draft had issues, mentor provided actionable direction: 'Not there yet. The situation is too vague\u2014\"in our recent go/no\u2011go meetings\" misses the single\u2011moment test. Keep the concrete chat quote, but anchor to last Thursday's 4 p.m. go/no\u2011go and resend your full draft'"
              },
              "C-04": {
                "verdict": "PASS",
                "evidence": "Mentor evaluated revisions specifically: 'That meets the bar. You anchored to a single meeting, kept the behavior camera\u2011visible with counts and the exact chat quote, and owned the impact with your feeling and a concrete consequence\u2014clean and strong.'"
              },
              "C-05": {
                "verdict": "PASS",
                "evidence": "When learner said draft was 'mostly fine,' mentor didn't correct immediately but guided exploration: 'Let's stress-test it with the S-B-I self-check. Ask yourself: does your situation name a single meeting, could a camera capture every behavior phrase as written...' allowing learner to discover issues themselves."
              },
              "C-06": {
                "verdict": "PASS",
                "evidence": "Mentor asked learner to explain reasoning: 'Walk me through how you landed on \"interrupted me twice\u2014once after I shared the open bug count and again as I started to outline the workaround\"; what were you trying to capture with that wording?'"
              },
              "C-07": {
                "verdict": "PASS",
                "evidence": "Mentor prompted reflection on learning process: 'Stepping back for a moment: what clicked for you in that revision?' and later 'what's the single phrasing habit you're most likely to slip back into that you'll watch for first?'"
              }
            },
            "overall": {
              "passed_count": 5,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "coaching_quality",
              "conversation_id": "91f1f846",
              "evaluated_at": "2026-01-21T10:54:55.164491"
            }
          }
        },
        "sbi_content": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "D-04": {
                "verdict": "PASS",
                "evidence": "Mentor asks 'Walk me through how you landed on \"interrupted me twice\u2014once after I shared the open bug count and again as I started to outline the workaround\"; what were you trying to capture with that wording?' This probes whether the learner understands the observable vs. interpretive distinction by asking them to articulate their reasoning for choosing specific observable language over judgment labels."
              },
              "D-05": {
                "verdict": "PASS",
                "evidence": "When learner struggled with vague situation ('in our standups lately'), mentor provided targeted scaffolding: 'Think of the most recent standup where it happened\u2014what were you updating on then?' This guided the learner to a specific moment without giving the full answer. Later, mentor also directed: 'Let's stress-test it with the S-B-I self-check' providing a structured technique to work through the difficulty."
              },
              "D-06": {
                "verdict": "PASS",
                "evidence": "Mentor provides multiple reusable tools: (1) 'S = calendar moment; B = camera could see/hear it; I = inside-my-skin feeling or direct consequence for me/my work. Strip judgment words.' (2) The 'camera test' heuristic referenced multiple times. (3) 'Your trigger\u2013action plan: the moment you spot a label, swap to camera\u2011visible with counts, then add one owned impact.' These are generalizable tools for future SBI drafting."
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "sbi_content",
              "conversation_id": "91f1f846",
              "evaluated_at": "2026-01-21T10:55:08.644717"
            }
          }
        },
        "adaptive_pacing": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "E-01": {
                "verdict": "PASS",
                "evidence": "Mentor checks readiness multiple times: 'ready to begin?' at start, 'What, if anything, would you tweak in that wording before we move on?', 'good to wrap?' at end. Also asks 'can you revise with that specific moment?' before expecting revision."
              },
              "E-02": {
                "verdict": "PASS",
                "evidence": "Early on, mentor provides detailed demo with explicit S-B-I breakdown and self-check tool. By second rep, mentor gives scenario but no stems/scaffolds. After learner succeeds, mentor shifts to reflection questions ('what clicked for you?', 'what's one principle you'll carry forward?') and asks learner to self-identify pitfalls rather than providing them."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "adaptive_pacing",
              "conversation_id": "91f1f846",
              "evaluated_at": "2026-01-21T10:55:19.750975"
            }
          }
        },
        "conversational_quality": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "F-01": {
                "verdict": "PASS",
                "evidence": "Mentor varies turn structure throughout: longer explanations with numbered lists (demo turn), short reactions ('That lands \ud83d\udc4d'), probing questions ('what were you trying to capture with that wording?'), brief affirmations ('Perfect'), and wrap-up checks ('good to wrap?'). Rhythm shifts between teaching, questioning, and acknowledging."
              },
              "F-02": {
                "verdict": "PASS",
                "evidence": "Mentor shows personality with reactions like 'That lands \ud83d\udc4d', 'Love it\u2014you're ready to put this in play', 'Nice catch' style affirmations, and casual phrasing like 'your trigger\u2013action plan is dialed in.' Uses emoji (\ud83d\udc4d) and conversational tone rather than purely neutral facilitation."
              },
              "F-03": {
                "verdict": "N/A",
                "evidence": "Learner never displays anxiety, frustration, or confusion throughout the transcript. Learner is cooperative and engaged, responding positively to corrections without emotional distress."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "na_count": 1,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "conversational_quality",
              "conversation_id": "91f1f846",
              "evaluated_at": "2026-01-21T10:55:31.879544"
            }
          }
        }
      }
    },
    {
      "langsmith_id": "4fb1ebe1-04e1-432f-a85d-b5828df92139",
      "short_id": "4fb1ebe1",
      "source_type": "dataset",
      "critical_verdict": "PASS",
      "critical_json": {
        "criteria": {
          "B-01": {
            "verdict": "PASS",
            "evidence": "Mentor demonstrates a complete SBI example: 'In Tuesday's standup, when I started my update, you began answering and spoke for about a minute while I was mid-sentence; I stopped speaking. I felt rushed and decided not to raise a blocker, and my task slipped a day.'"
          },
          "C-01": {
            "verdict": "PASS",
            "evidence": "Mentor points to specific language: 'does \"Lately\u2026 in meetings\" pass the single\u2011moment test' and 'How does \"disengaged\" fare on the camera test\u2014would audio/video capture that word'"
          },
          "C-03": {
            "verdict": "PASS",
            "evidence": "After feedback on vague draft, mentor requests revision: 'use that anchor. Write your feedback in 2\u20133 sentences: name Monday's 9am standup right as you started your update...' and later 'Can you anchor this to last Thursday's cross\u2011functional design review... and rewrite it in 2\u20133 sentences?'"
          },
          "D-01": {
            "verdict": "PASS",
            "evidence": "When learner uses 'Lately in our team meetings,' mentor catches it: 'You marked the moment as passing, but earlier you called \"Lately in our team meetings\" too vague\u2014what single meeting/moment will you anchor to instead?'"
          },
          "D-02": {
            "verdict": "PASS",
            "evidence": "Mentor catches judgment words 'disengaged' and 'dismissive': 'How does \"disengaged\" fare on the camera test\u2014would audio/video capture that word, or would you need something more concrete?' Also catches 'dismissive' and 'unprofessional' in later draft by asking learner to rewrite anchored to specific moment."
          },
          "D-03": {
            "verdict": "PASS",
            "evidence": "When learner writes 'made the Director and the group uncomfortable,' mentor prompts revision to anchor to specific moment and rewrite, resulting in learner using owned 'I' statements: 'I felt thrown off and skipped the context slide'"
          },
          "E-03": {
            "verdict": "PASS",
            "evidence": "When mentor could have given answers, they instead prompt learner to self-check first: 'Before I weigh in, what's the one phrase you think I'll push back on, and why?' and 'Run the self-check on your draft\u2014moment, behavior, impact, and a leak scan\u2014and tell me what passes and what doesn't.'"
          }
        },
        "overall": {
          "verdict": "PASS",
          "summary": "The mentor demonstrates all critical tutoring behaviors: modeling SBI, providing specific feedback with quoted language, requesting revisions, catching vague situations and judgment leakage, addressing accusatory impact, and protecting productive struggle.",
          "passed_count": 7,
          "failed_count": 0,
          "na_count": 0,
          "failed_criteria": []
        },
        "_metadata": {
          "judge_id": "critical_criteria",
          "conversation_id": "4fb1ebe1",
          "evaluated_at": "2026-01-21T10:55:47.746705"
        }
      },
      "quality_results": {
        "session_setup": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "A-01": {
                "verdict": "PASS",
                "evidence": "Mentor states: 'We're working on delivering peer feedback using the SBI framework. Success = a concrete moment, camera-testable behavior, and owned impact\u2014twice: first with support, then solo.'"
              },
              "A-02": {
                "verdict": "PASS",
                "evidence": "Mentor signals transitions: 'I'll demonstrate how I approach it, then we'll switch to you' and later 'Your turn\u2014pick a real, recent moment with a peer'"
              },
              "A-03": {
                "verdict": "PASS",
                "evidence": "Scenarios include specific workplace situations: 'Tuesday's standup' with speaking over during updates, 'Monday's 9am team standup,' and 'last Thursday's cross-functional design review with our Director on the call' with a senior PM cutting in\u2014all with plausible interpersonal dynamics"
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "session_setup",
              "conversation_id": "4fb1ebe1",
              "evaluated_at": "2026-01-21T10:55:57.427304"
            }
          }
        },
        "modeling_quality": {
          "passed": 4,
          "total": 4,
          "json": {
            "criteria": {
              "B-02": {
                "verdict": "PASS",
                "evidence": "\"I chose observable verbs over labels (not 'you dominated'), and I owned the impact with my feeling and the direct consequence, not 'it was unprofessional.'\" - Mentor explains WHY they made specific word choices during the demonstration."
              },
              "B-03": {
                "verdict": "PASS",
                "evidence": "\"I chose observable verbs over labels (not 'you dominated')\" - Mentor explicitly shows an alternative they rejected ('you dominated') and explains why they chose different phrasing, demonstrating a choice point."
              },
              "B-04": {
                "verdict": "PASS",
                "evidence": "\"My self-check: - Moment: can someone who wasn't there picture the exact meeting/point? - Behavior: would a camera/mic capture what I wrote (verbs, not labels or motives)? - Impact: starts with 'I,' names my feeling and/or a direct consequence I experienced. - Leak scan: replace judgment words...\" - Mentor explicitly models a verification checklist."
              },
              "B-05": {
                "verdict": "PASS",
                "evidence": "\"would a camera/mic capture what I wrote\" (the camera test) and \"Pick one moment, describe what a camera would capture (no labels), and name my 'I' impact\" - Multiple reusable heuristics offered that learner can apply independently."
              }
            },
            "overall": {
              "passed_count": 4,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "modeling_quality",
              "conversation_id": "4fb1ebe1",
              "evaluated_at": "2026-01-21T10:56:08.418057"
            }
          }
        },
        "coaching_quality": {
          "passed": 5,
          "total": 5,
          "json": {
            "criteria": {
              "C-02": {
                "verdict": "PASS",
                "evidence": "Mentor provides actionable direction: 'Can you anchor this to last Thursday's cross\u2011functional design review with our Director\u2014right as you began presenting and the PM cut in\u2014instead of \"Lately\u2026,\" and rewrite it in 2\u20133 sentences?' Also earlier: 'use that anchor. Write your feedback in 2\u20133 sentences: name Monday's 9am standup right as you started your update, describe what was seen/heard (no labels), and name your own feeling or direct consequence you experienced.'"
              },
              "C-04": {
                "verdict": "PASS",
                "evidence": "Mentor specifically evaluates revisions: 'That meets the bar\u2014anchored, camera-testable, and owned impact.' And later: 'That lands\u2014anchored to a specific moment, camera\u2011testable behavior, and an owned, concrete impact. No judgment leaks, and the stakes are clear without adding heat.'"
              },
              "C-05": {
                "verdict": "PASS",
                "evidence": "Mentor explores errors before correcting: 'Quick check: does \"Lately\u2026 in meetings\" pass the single\u2011moment test\u2014could someone picture the exact meeting you mean?' and 'How does \"disengaged\" fare on the camera test\u2014would audio/video capture that word, or would you need something more concrete?' Also: 'You marked the moment as passing, but earlier you called \"Lately in our team meetings\" too vague\u2014what single meeting/moment will you anchor to instead?'"
              },
              "C-06": {
                "verdict": "PASS",
                "evidence": "Mentor asks learner to explain reasoning: 'Why that moment\u2014what made you choose Monday's 9am standup right when you started your update as the anchor?' and 'If I were to push on one part of your draft, what would it be\u2014and why do you think that might be a weak spot?'"
              },
              "C-07": {
                "verdict": "PASS",
                "evidence": "Mentor prompts reflection on learning: 'What principle from this will you carry forward when you're giving SBI feedback under higher stakes?' Learner responds with synthesized principle, and mentor affirms: 'That's the core\u2014you locked onto the control move...'"
              }
            },
            "overall": {
              "passed_count": 5,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "coaching_quality",
              "conversation_id": "4fb1ebe1",
              "evaluated_at": "2026-01-21T10:56:22.795980"
            }
          }
        },
        "sbi_content": {
          "passed": 3,
          "total": 3,
          "json": {
            "criteria": {
              "D-04": {
                "verdict": "PASS",
                "evidence": "Mentor asks 'How does \"disengaged\" fare on the camera test\u2014would audio/video capture that word, or would you need something more concrete?' This directly probes whether the learner can distinguish between observable behavior and interpretive labels."
              },
              "D-05": {
                "verdict": "PASS",
                "evidence": "When learner struggled with anchoring to a specific moment, mentor provided targeted scaffolding: 'can you anchor this to last Thursday's cross\u2011functional design review with our Director\u2014right as you began presenting and the PM cut in\u2014instead of \"Lately\u2026\"' - giving a specific moment to use rather than generic encouragement."
              },
              "D-06": {
                "verdict": "PASS",
                "evidence": "Mentor provides multiple reusable tools: the 'camera test' heuristic, a self-check framework (Moment/Behavior/Impact/Leak scan), and a one-line cue: 'Pick one moment, describe what a camera would capture (no labels), and name my \"I\" impact.'"
              }
            },
            "overall": {
              "passed_count": 3,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "sbi_content",
              "conversation_id": "4fb1ebe1",
              "evaluated_at": "2026-01-21T10:56:35.683072"
            }
          }
        },
        "adaptive_pacing": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "E-01": {
                "verdict": "PASS",
                "evidence": "Multiple readiness checks: 'Ready to try a quick spot-check on an example using this?', 'Ready to dive in?', and before advancing to solo practice: 'Your turn\u2014pick a real, recent moment...' after confirming learner understood the self-check."
              },
              "E-02": {
                "verdict": "PASS",
                "evidence": "Early on, mentor provides detailed self-check framework and walks through each criterion. Later, after learner demonstrates competence with 'In Monday's 9am standup...' draft, mentor simply says 'That meets the bar' and moves to variation without detailed scaffolding. Final drafts receive brief confirmation ('That lands') rather than step-by-step guidance."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "adaptive_pacing",
              "conversation_id": "4fb1ebe1",
              "evaluated_at": "2026-01-21T10:56:47.130202"
            }
          }
        },
        "conversational_quality": {
          "passed": 2,
          "total": 2,
          "json": {
            "criteria": {
              "F-01": {
                "verdict": "PASS",
                "evidence": "Turn structure varies: longer explanations ('Here's how I'd approach it, thinking out loud...'), short affirmations ('Good catch on the moment'), questions ('What stands out to you in that draft?'), brief closings ('That's it \ud83d\udc4d'), and mid-length coaching prompts. Not a repetitive formula."
              },
              "F-02": {
                "verdict": "PASS",
                "evidence": "Shows personality with 'That's it \ud83d\udc4d', 'Thanks for taking a swing', 'Nicely done today', and 'Glad to hear it.' These add warmth beyond neutral facilitation."
              },
              "F-03": {
                "verdict": "N/A",
                "evidence": "Learner never displays anxiety, frustration, or confusion throughout the transcript. They respond cooperatively and confidently throughout."
              }
            },
            "overall": {
              "passed_count": 2,
              "failed_count": 0,
              "na_count": 1,
              "pass_rate": 1.0,
              "failed_criteria": []
            },
            "_metadata": {
              "judge_id": "conversational_quality",
              "conversation_id": "4fb1ebe1",
              "evaluated_at": "2026-01-21T10:56:58.211064"
            }
          }
        }
      }
    }
  ],
  "summary": {
    "total_evaluated": 6,
    "critical_passed": 6,
    "critical_failed": 0,
    "quality_passed": 109,
    "quality_total": 114
  }
};
        const metrics = {"total": 6, "completed": 6, "critical_passed": 6, "critical_failed": 0, "critical_pass_rate": 100.0, "quality_total_passed": 109, "quality_total_criteria": 114, "quality_average": 95.6, "per_criteria": {"session_setup": {"passed": 18, "total": 18, "individual": {"A-01": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "A-02": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "A-03": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}}, "by_persona": {"amara_SBI": {"passed": 0, "total": 0}, "bailey_SBI": {"passed": 0, "total": 0}, "carlos_SBI": {"passed": 0, "total": 0}, "daniel_SBI": {"passed": 0, "total": 0}, "elise_SBI": {"passed": 0, "total": 0}, "fatou_SBI": {"passed": 0, "total": 0}}, "percentage": 100.0}, "modeling_quality": {"passed": 20, "total": 24, "individual": {"B-02": {"passed": 5, "failed": 1, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "B-03": {"passed": 5, "failed": 1, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "B-04": {"passed": 4, "failed": 2, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "B-05": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}}, "by_persona": {"amara_SBI": {"passed": 0, "total": 0}, "bailey_SBI": {"passed": 0, "total": 0}, "carlos_SBI": {"passed": 0, "total": 0}, "daniel_SBI": {"passed": 0, "total": 0}, "elise_SBI": {"passed": 0, "total": 0}, "fatou_SBI": {"passed": 0, "total": 0}}, "percentage": 83.3}, "coaching_quality": {"passed": 30, "total": 30, "individual": {"C-02": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "C-04": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "C-05": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "C-06": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "C-07": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}}, "by_persona": {"amara_SBI": {"passed": 0, "total": 0}, "bailey_SBI": {"passed": 0, "total": 0}, "carlos_SBI": {"passed": 0, "total": 0}, "daniel_SBI": {"passed": 0, "total": 0}, "elise_SBI": {"passed": 0, "total": 0}, "fatou_SBI": {"passed": 0, "total": 0}}, "percentage": 100.0}, "sbi_content": {"passed": 18, "total": 18, "individual": {"D-04": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "D-05": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "D-06": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}}, "by_persona": {"amara_SBI": {"passed": 0, "total": 0}, "bailey_SBI": {"passed": 0, "total": 0}, "carlos_SBI": {"passed": 0, "total": 0}, "daniel_SBI": {"passed": 0, "total": 0}, "elise_SBI": {"passed": 0, "total": 0}, "fatou_SBI": {"passed": 0, "total": 0}}, "percentage": 100.0}, "adaptive_pacing": {"passed": 11, "total": 12, "individual": {"E-01": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "E-02": {"passed": 5, "failed": 1, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}}, "by_persona": {"amara_SBI": {"passed": 0, "total": 0}, "bailey_SBI": {"passed": 0, "total": 0}, "carlos_SBI": {"passed": 0, "total": 0}, "daniel_SBI": {"passed": 0, "total": 0}, "elise_SBI": {"passed": 0, "total": 0}, "fatou_SBI": {"passed": 0, "total": 0}}, "percentage": 91.7}, "conversational_quality": {"passed": 12, "total": 12, "individual": {"F-01": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "F-02": {"passed": 6, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}, "F-03": {"passed": 0, "failed": 0, "by_persona": {"amara_SBI": {"passed": 0, "failed": 0}, "bailey_SBI": {"passed": 0, "failed": 0}, "carlos_SBI": {"passed": 0, "failed": 0}, "daniel_SBI": {"passed": 0, "failed": 0}, "elise_SBI": {"passed": 0, "failed": 0}, "fatou_SBI": {"passed": 0, "failed": 0}}}}, "by_persona": {"amara_SBI": {"passed": 0, "total": 0}, "bailey_SBI": {"passed": 0, "total": 0}, "carlos_SBI": {"passed": 0, "total": 0}, "daniel_SBI": {"passed": 0, "total": 0}, "elise_SBI": {"passed": 0, "total": 0}, "fatou_SBI": {"passed": 0, "total": 0}}, "percentage": 100.0}}, "personas_seen": [], "persona_letters": {"amara_SBI": "A", "bailey_SBI": "B", "carlos_SBI": "C", "daniel_SBI": "D", "elise_SBI": "E", "fatou_SBI": "F"}};

        function escapeHtml(text) {
            if (!text) return '';
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        function extractPersona(conv) {
            // Try to extract persona from run_name or transcript
            if (conv.run_name) {
                const match = conv.run_name.match(/([a-z]+_[A-Z]+)/i);
                if (match) return match[1];
            }
            // Fallback: check transcript for persona mentions
            return conv.persona || 'Unknown';
        }

        function renderCriteriaTable() {
            const thead = document.getElementById('criteria-header');
            const tbody = document.getElementById('criteria-table');
            const perCriteria = metrics.per_criteria || {};
            const personasSeen = metrics.personas_seen || [];
            const personaLetters = metrics.persona_letters || {};
            const numPersonaCols = personasSeen.length;
            const totalCols = 4 + numPersonaCols;

            // Render header
            let headerHtml = '<tr><th>Criterion</th><th>Passed</th><th>Pass Rate</th>';
            personasSeen.forEach(p => {
                headerHtml += `<th style="width: 40px; text-align: center" title="${p}">${personaLetters[p] || p[0].toUpperCase()}</th>`;
            });
            headerHtml += '<th style="width: 25%">Progress</th></tr>';
            thead.innerHTML = headerHtml;

            Object.entries(perCriteria).forEach(([judgeId, data], index) => {
                const percentage = data.percentage || 0;
                const progressClass = percentage >= 80 ? 'high' : percentage >= 50 ? 'medium' : 'low';
                const byPersona = data.by_persona || {};

                // Main row
                const row = document.createElement('tr');
                row.className = 'criteria-expand-row';
                row.onclick = () => toggleCriteriaDetails(index);
                let rowHtml = `
                    <td>${judgeId.replace(/_/g, ' ').replace(/\b\w/g, l => l.toUpperCase())}</td>
                    <td>${data.passed}/${data.total}</td>
                    <td>${percentage}%</td>
                `;
                // Add persona columns
                personasSeen.forEach(p => {
                    const pData = byPersona[p] || {passed: 0, total: 0};
                    const pPct = pData.total > 0 ? Math.round(pData.passed / pData.total * 100) : '-';
                    const pClass = pPct === '-' ? '' : (pPct >= 80 ? 'pass' : 'fail');
                    rowHtml += `<td style="text-align: center" class="${pClass}">${pPct}${pPct !== '-' ? '%' : ''}</td>`;
                });
                // Progress bar at end
                rowHtml += `<td>
                    <div class="progress-bar">
                        <div class="progress-fill ${progressClass}" style="width: ${percentage}%"></div>
                    </div>
                </td>`;
                row.innerHTML = rowHtml;
                tbody.appendChild(row);

                // Details row with individual criteria
                const detailsRow = document.createElement('tr');
                detailsRow.className = 'criteria-details-row';
                detailsRow.id = `criteria-details-${index}`;

                const individual = data.individual || {};
                const sortedCriteria = Object.entries(individual).sort((a, b) => a[0].localeCompare(b[0]));

                // Add individual criteria as sub-rows (same format as main rows)
                sortedCriteria.forEach(([code, stats]) => {
                    const total = stats.passed + stats.failed;
                    const hasFail = stats.failed > 0;
                    const pct = total > 0 ? Math.round(stats.passed / total * 100) : 0;
                    const progressClass = pct >= 80 ? 'high' : pct >= 50 ? 'medium' : 'low';
                    const cByPersona = stats.by_persona || {};

                    const subRow = document.createElement('tr');
                    subRow.className = 'criteria-details-row';
                    subRow.id = `criteria-details-${index}-${code}`;

                    let subRowHtml = `
                        <td style="padding-left: 2rem; color: #6b7280;">${code}</td>
                        <td>${stats.passed}/${total}</td>
                        <td>${pct}%</td>
                    `;
                    // Add persona columns
                    personasSeen.forEach(p => {
                        const ps = cByPersona[p] || {passed: 0, failed: 0};
                        const pTotal = ps.passed + ps.failed;
                        const pPct = pTotal > 0 ? Math.round(ps.passed / pTotal * 100) : '-';
                        const pClass = pPct === '-' ? '' : (pPct >= 80 ? 'pass' : 'fail');
                        subRowHtml += `<td style="text-align: center" class="${pClass}">${pPct}${pPct !== '-' ? '%' : ''}</td>`;
                    });
                    // Progress bar at end
                    subRowHtml += `<td>
                        <div class="progress-bar">
                            <div class="progress-fill ${progressClass}" style="width: ${pct}%"></div>
                        </div>
                    </td>`;
                    subRow.innerHTML = subRowHtml;
                    tbody.appendChild(subRow);
                });
            });
        }

        function toggleCriteriaDetails(index) {
            const row = document.querySelectorAll('.criteria-expand-row')[index];
            row.classList.toggle('open');
            // Toggle all sub-rows for this index
            document.querySelectorAll(`[id^="criteria-details-${index}-"]`).forEach(el => {
                el.classList.toggle('open');
            });
        }

        function renderCriteriaEvidence(criteria, showAll = false) {
            if (!criteria || Object.keys(criteria).length === 0) {
                return '<em>No criteria data available</em>';
            }

            // Separate failed and passed criteria
            const failed = [];
            const passed = [];
            for (const [code, data] of Object.entries(criteria)) {
                if (data.verdict === 'FAIL') {
                    failed.push({ code, ...data });
                } else if (data.verdict === 'PASS') {
                    passed.push({ code, ...data });
                }
            }

            let html = '';

            // Always show failed criteria first and prominently
            if (failed.length > 0) {
                html += '<div class="failed-summary"><div class="failed-summary-title">Failed Criteria (' + failed.length + ')</div>';
                failed.forEach(item => {
                    html += `<div class="criterion-item fail">
                        <div class="criterion-header">
                            <span class="criterion-code">${item.code}</span>
                            <span class="verdict fail">FAIL</span>
                        </div>
                        <div class="evidence-text">${escapeHtml(item.evidence)}</div>
                    </div>`;
                });
                html += '</div>';
            }

            // Show passed criteria (collapsed by default if there are many)
            if (passed.length > 0 && showAll) {
                html += '<div class="passed-criteria">';
                passed.forEach(item => {
                    html += `<div class="criterion-item pass">
                        <div class="criterion-header">
                            <span class="criterion-code">${item.code}</span>
                            <span class="verdict pass">PASS</span>
                        </div>
                        <div class="evidence-text">${escapeHtml(item.evidence)}</div>
                    </div>`;
                });
                html += '</div>';
            } else if (passed.length > 0) {
                html += `<div class="toggle-evidence" onclick="this.nextElementSibling.classList.toggle('expanded'); this.textContent = this.nextElementSibling.classList.contains('expanded') ? 'Hide ${passed.length} passed criteria' : 'Show ${passed.length} passed criteria'">Show ${passed.length} passed criteria</div>`;
                html += '<div class="criteria-list">';
                passed.forEach(item => {
                    html += `<div class="criterion-item pass">
                        <div class="criterion-header">
                            <span class="criterion-code">${item.code}</span>
                            <span class="verdict pass">PASS</span>
                        </div>
                        <div class="evidence-text">${escapeHtml(item.evidence)}</div>
                    </div>`;
                });
                html += '</div>';
            }

            return html;
        }

        function renderConversations() {
            const tbody = document.getElementById('conversations');
            const conversations = manifest.conversations || [];

            conversations.forEach((conv, index) => {
                const criticalVerdict = conv.critical_verdict || 'PENDING';
                const criticalJson = conv.critical_json || {};
                const qualityResults = conv.quality_results || {};

                // Calculate quality score
                let qualityPassed = 0;
                let qualityTotal = 0;
                for (const [judge, result] of Object.entries(qualityResults)) {
                    qualityPassed += result.passed || 0;
                    qualityTotal += result.total || 0;
                }
                const qualityScore = qualityTotal > 0 ? `${qualityPassed}/${qualityTotal}` : '-';

                // Extract persona
                const persona = extractPersona(conv);

                // Main row
                const row = document.createElement('tr');
                row.className = 'expandable';
                row.onclick = () => toggleDetails(index);
                row.innerHTML = `
                    <td>${conv.short_id}</td>
                    <td><span class="persona-tag">${persona}</span></td>
                    <td><span class="verdict ${criticalVerdict.toLowerCase()}">${criticalVerdict}</span></td>
                    <td>${qualityScore}</td>
                    <td><span class="verdict ${criticalVerdict === 'PENDING' ? 'pending' : 'pass'}">
                        ${criticalVerdict === 'PENDING' ? 'Pending' : 'Complete'}
                    </span></td>
                `;
                tbody.appendChild(row);

                // Details row with full evidence
                const detailsRow = document.createElement('tr');
                detailsRow.className = 'details';
                detailsRow.id = `details-${index}`;

                let detailsHtml = '<td colspan="5"><div class="details-content">';

                // Quality summary grid
                if (Object.keys(qualityResults).length > 0) {
                    detailsHtml += '<div class="quality-grid" style="margin-bottom: 1rem;">';
                    for (const [judge, result] of Object.entries(qualityResults)) {
                        const passed = result.passed || 0;
                        const total = result.total || 0;
                        const pct = total > 0 ? Math.round(passed / total * 100) : 0;
                        detailsHtml += `<div class="quality-item"><span>${judge.replace(/_/g, ' ')}</span><span>${passed}/${total} (${pct}%)</span></div>`;
                    }
                    detailsHtml += '</div>';
                }

                // Critical criteria evidence
                if (criticalJson.criteria) {
                    detailsHtml += '<div class="evidence-section">';
                    detailsHtml += '<h4>Critical Criteria Evidence</h4>';
                    detailsHtml += renderCriteriaEvidence(criticalJson.criteria);
                    detailsHtml += '</div>';
                }

                // Quality judges evidence
                for (const [judgeName, result] of Object.entries(qualityResults)) {
                    if (result.json && result.json.criteria) {
                        detailsHtml += '<div class="judge-section">';
                        detailsHtml += `<h5>${judgeName.replace(/_/g, ' ')}</h5>`;
                        detailsHtml += renderCriteriaEvidence(result.json.criteria);
                        detailsHtml += '</div>';
                    }
                }

                if (!criticalJson.criteria && Object.keys(qualityResults).length === 0) {
                    detailsHtml += '<em>No evaluation data yet</em>';
                }

                detailsHtml += '</div></td>';
                detailsRow.innerHTML = detailsHtml;
                tbody.appendChild(detailsRow);
            });
        }

        function toggleDetails(index) {
            const details = document.getElementById(`details-${index}`);
            details.classList.toggle('open');
        }

        renderCriteriaTable();
        renderConversations();
    </script>
</body>
</html>